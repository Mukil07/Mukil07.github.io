<!DOCTYPE HTML>
<html lang="en">
	<head>
	  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	  <title>Mukilan Karuppasamy</title>
	  <meta name="author" content="Mukilan Karuppasamy">
	  <meta name="viewport" content="width=device-width, initial-scale=1">
	  <link rel="shortcut icon" href="images/mukil2.jpg" type="image/x-icon">
	  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	</head>

  <body>
    
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Mukilan Karuppasamy
                </p>
                <p>
		I'm a predoctoral researcher at <a href="https://visual-computing.in/">IISc</a>, Bangalore, working with <a href="https://anirbanchakraborty.github.io/">Anirban Chakraborty</a> on visual instruction tuning for multimodal large language models. 
			Previously, I had the opportunity to work with <a href="https://faculty.iiit.ac.in/~jawahar/">CV Jawahar</a> at IIIT Hyderabad on concept-based interpretability in video action recognition, 
			and with <a href="https://www.cecs.ucf.edu/faculty/yogesh-singh-rawat/">Yogesh Singh Rawat</a> at CRCV, UCF, on robustness analysis of vision-language models. 
			I was also a <a href="https://www.mitacs.ca/our-programs/globalink-research-internship-students/">MITACS Globalink Fellow</a> in 2023, working on distributed message passing with <a href="https://home.cc.umanitoba.ca/~mezghana/">Amine Mezhghani</a> 
			and <a href="https://home.cc.umanitoba.ca/~bellilif/">Faouzi Bellili</a> at the University of Manitoba. Earlier, I worked on virtual try-on systems using GANs with <a href="https://web.iitd.ac.in/~brejesh/">Brejesh Lall</a> at IIT Delhi.
                <p style="text-align:center">
                  <a href="mailto:mukilan.nitt@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://drive.google.com/file/d/1gpr5pCjQlAD8z1Qko6uOpJXDnUhHaAu4/view?usp=sharing">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=lepAbWsAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Mukil07">Github</a> &nbsp;/&nbsp;
		  <a href="https://www.linkedin.com/in/mukilan-k-3261121b9/">Linkedin</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
		<a href="images/mukil2.jpg">
		  <img
		    src="images/mukil2.jpg"
		    alt="profile photo"
		    style="width: 180px; height: auto; object-fit: cover; border-radius: 8px;"
		    class="hoverZoomLink"
		  >
		</a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, interpretability, and robustness analysis. My current interest lies in understanding the theoretical basis of interpretability in overparameterized deep neural networks. Some papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="VCBM_stop()" onmouseover="VCBM_start()"  bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <img src='images/VCBM.png' width=100%>
        </div>
        <script type="text/javascript">
          function VCBM_start() {
            document.getElementById('VCBM').style.opacity = "1";
          }

          function VCBM_stop() {
            document.getElementById('VCBM').style.opacity = "0";
          }
          VCBM_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://mukil07.github.io/VCBM.github.io/">
          <span class="papertitle">Towards Safer and Understandable Driver Intention Prediction</span>
        </a>
        <br>
        <strong>Mukilan Karuppasamy</strong>,
        <a href="https://sites.google.com/site/shankarsetty/home">Shankar Gangisetty</a>,
        <a href="https://shyamnandan.netlify.app/">Shyam Nandan Rai</a>,
        <a href="https://cmas1.github.io/">Carlo Masone</a>,
        <a href="https://faculty.iiit.ac.in/~jawahar/">CV Jawahar</a>,

        <br>
        <em>ICCV</em>, 2025
        <br>
        <a href="https://mukil07.github.io/VCBM.github.io/">project page</a>
        /
        <a href="https://szymanowiczs.github.io/VCBM">arXiv</a>
        <p></p>
        <p>
		Proposed a concept based inherently intrepretable model for Video models using concept bottleneck model and token merging. This was applied in Driver Intention Prediction task.
        </p>
      </td>
    </tr>




    <tr onmouseout="dvamp_stop()" onmouseover="dvamp_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <img src='images/dvamp.png' width=100%>
        </div>
        <script type="text/javascript">
          function dvamp_start() {
            document.getElementById('dvamp').style.opacity = "1";
          }

          function dvamp_stop() {
            document.getElementById('dvamp').style.opacity = "0";
          }
          dvamp_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        
        <span class="papertitle">Distributed Vector Approximate Message Passing</span>
        
        <br>
	<strong>Mukilan Karuppasamy</strong>,
        <a href="https://makrout.github.io/">Mohamed Akrout</a>,
        <a href="https://home.cc.umanitoba.ca/~mezghana/">Amine Mezghani</a>,
        <a href="https://home.cc.umanitoba.ca/~bellilif/">Faouzi Bellili</a>,
        <br>
        <em>ICASSP</em>, 2024 &nbsp <font color=#FF8080></font>
        <br>
        <a href="https://github.com/Mukil07/Distributed-Vector-Approximate-Message-Passing">github</a>
        /
        <a href="https://ieeexplore.ieee.org/abstract/document/10446383">pdf</a>
        <p></p>
        <p>
				Derived a collaborative signal estimation from multiple agents with different measurement channels through distributed message passing algorithm.
        </p>
      </td>
    </tr>

    <tr onmouseout="Onion_stop()" onmouseover="Onion_start()"  >
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <img src='images/model_size_page-0001.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function Onion_start() {
            document.getElementById('Onion').style.opacity = "1";
          }

          function Onion_stop() {
            document.getElementById('Onion').style.opacity = "0";
          }
          Onion_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="">
          <span class="papertitle">Pixel Onion: Peeling Layers of Zero-Shot Object Detection in Pixelation</span>
        </a>
        <br>
	<a href="https://ppriyank.github.io/">Priyank Pathak*</a>,
        <strong>Mukilan Karuppasamy*</strong>,
        <a href="https://scholar.google.com/citations?user=2pHFEhMAAAAJ&hl=en">Aaditya Baranwal</a>,
        <a href="https://scholar.google.com/citations?user=tg4LJ94AAAAJ&hl=en">Shyam Marjit</a>,
        <a href="https://scholar.google.com/citations?hl=en&user=15YqUQUAAAAJ">Shruti Vyas</a>,
        <a href="https://www.cs.ucf.edu/person/yogeshrawat/"> Yogesh S. Rawat</a>,
	<br>
        <em>* equal contribution</em>,
        <br>
        <em>Under Review</em>
        <br>
        <p></p>
        <p>
		We critically examine the vulnerability of SOTA Zero-Shot Object Detectors with 50 different backbones to resolution degradation (`pixelation'). Two key takeaways are 1) The choice of backbone alone can substantially enhance robustness, while prompting (language) plays a minimal role. 2) Robustness is also a function of the dataset/domain of images at inference. A certain type of image are not affected by pixelation.
        </p>
      </td>
    </tr>
	
    <tr onmouseout="Sketch_stop()" onmouseover="Sketch_start()" >
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <img src='images/SketchLLM_page-0001.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function Sketch_start() {
            document.getElementById('Sketch').style.opacity = "1";
          }

          function Sketch_stop() {
            document.getElementById('Sketch').style.opacity = "0";
          }
          Sketch_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="">
          <span class="papertitle">O3SLM: Open Weight, Open Data, and Open Vocabulary Sketch-Language Model</span>
        </a>
        <br>
        
        <a href="">Rishi Gupta*</a>,
		<strong>Mukilan Karuppasamy*</strong>,
        <a href="https://scholar.google.com/citations?user=tg4LJ94AAAAJ&hl=en">Shyam Marjit</a>,
        <a href="https://scholar.google.com/citations?user=rDCT8xQAAAAJ&hl=en">Aditay Tripathi</a>,
        <a href="https://anirbanchakraborty.github.io/">Anirban Chakraborty</a>,
		<br>
		<em>* equal contribution</em>
        <br>
        <em>Under Review</em>
        <br>
        <p></p>
        <p>
		Proposed a large scale sketch based pretraining and visual instruction tuning dataset with 30M instances. Developed a state of the art Sketch based Multimodal model which can perform detection, Counting, VQA, SBIR with any crude, hand drawn sketches as the query instead of natural language. 
        </p>
      </td>
    </tr>
	
  </body>
</html>
